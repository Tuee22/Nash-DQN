This repository contains the code for the Nash-DQN algorithm for general-sum multi-agent reinforcement learning.
The associated paper "Deep Q-Learning for Nash Equilibria: Nash-DQN" can be found at https://arxiv.org/abs/1904.10554.

INSTRUCTIONS:

To generate plots based on pre-trained network:
- Open file "Visualization.ipynb" and run all cells

To train network based on default parameters:
- Open file "Training.ipynb" and run cell with appropiate parameters
- Open file "Visualization.ipynb"
- Change variable net_file_name to the designated file name of Action Network
- Run all cells to generate plots

MN: to run in a container type:
```bash
docker build -t nash .
docker run --runtime=nvidia --rm -it -p 8000:8000 -v ./Nash DQN - Final:/work/notebooks nash
```
